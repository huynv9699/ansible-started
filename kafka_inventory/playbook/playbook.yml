---

- hosts: all
  remote_user: vagrant
  tasks:
    - name: Include kafka role
      include_role:
        name: ../../roles/kafka
  vars:
    ## Installation options
    kafka_app_dir: /u01/apps/kafka
    kafka_data_dir: /u01/data/kafka
    kafka_log_dir: /u01/logs/kafka
    kafka_scala_version: 2.13
    kafka_version: 3.2.3
    kafka_download_url: "https://dlcdn.apache.org/kafka/{{ kafka_version }}/kafka_{{ kafka_scala_version }}-{{ kafka_version }}.tgz"
    kafka_download_local_dir: /tmp
    kafka_cluster: "kafka-cluster"
    enable_download_binary: false
    kraft_enabled: true

    ## tunning system
    disable_swap: true
    sysctl_settings:
      - param: "vm.max_map_count"
        value: "300000"
      - param: "fs.file-max"
        value: "65536"
      - param: "net.ipv6.conf.all.disable_ipv6"
        value: "1"
      - param: "net.ipv6.conf.default.disable_ipv6"
        value: "1"

    ## Network
    kafka_bind_interface: eth1
    kafka_bind_address: "{{ hostvars[inventory_hostname]['ansible_' + kafka_bind_interface]['ipv4']['address'] }}"
    kafka_listener_port: 9092

    # The Java heap size (memory) allocation (xmx, xms)
    kafka_java_heap: "-Xms1G -Xmx1G"

    # kafka general configuration
    kafka_user: kafka
    kafka_group: "{{ kafka_user }}"

    ############################# Server Basics #############################

    # The id of the broker. This must be set to a unique integer for each broker.
    kafka_broker_id: 0

    # Enable auto creation of topic on the server
    kafka_auto_create_topics_enable: false
    # Enables delete topic. Delete topic through the admin tool will have no
    # effect if this config is turned off
    kafka_delete_topic_enable: true
    # Default replication factor for automatically created topics.
    kafka_default_replication_factor: 3
    # The number of threads to use for various background processing tasks
    kafka_background_threads: 10

    ############################# Socket Server Settings #############################

    # The address the socket server listens on. It will get the value returned from
    # java.net.InetAddress.getCanonicalHostName() if not configured.
    #   FORMAT:
    #     listeners = security_protocol://host_name:port
    #   EXAMPLE:
    #     listeners = PLAINTEXT://your.host.name:9092
    # listeners=PLAINTEXT://:9092
    kafka_listeners:
      - "PLAINTEXT://{{ kafka_bind_address }}:{{ kafka_listener_port }}"
      - "CONTROLLER://{{ kafka_bind_address }}:{{ kraft_listener_port }}"

    # Hostname and port the broker will advertise to producers and consumers. If not set,
    # it uses the value for "listeners" if configured.  Otherwise, it will use the value
    # returned from java.net.InetAddress.getCanonicalHostName().
    # advertised.listeners=PLAINTEXT://your.host.name:9092
    kafka_advertised_listeners:
      - "PLAINTEXT://{{ kafka_bind_address }}:{{ kafka_listener_port }}"

    # The number of threads handling network requests
    kafka_num_network_threads: 5
    # The number of threads that the server uses for processing requests, which may include disk I/O
    kafka_num_io_threads: 8
    # Specify the number of threads that are used to replicate messages from a source broker.
    # Increasing this value can lead to increased parallelism in I/O operations in the broker.
    kafka_num_replica_fetchers: 3

    # The send buffer (SO_SNDBUF) used by the socket server
    kafka_socket_send_buffer_bytes: 102400
    # The receive buffer (SO_RCVBUF) used by the socket server
    kafka_socket_receive_buffer_bytes: 102400
    # The maximum size of a request that the socket server will accept (protection against OOM)
    kafka_socket_request_max_bytes: 104857600
    # The socket receive buffer for network requests
    kafka_replica_socket_receive_buffer_bytes: 65536
    kafka_controller_socket_timeout_ms: 30000

    ############################# Log Basics #############################

    # A comma separated list of directories under which to store data log files
    kafka_data_log_dirs: "{{ kafka_data_dir }}"

    # The default number of log partitions per topic. More partitions allow greater
    # parallelism for consumption, but this will also result in more files across
    # the brokers.
    kafka_num_partitions: 1

    # The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.
    # This value is recommended to be increased for installations with data dirs located in RAID array.
    kafka_num_recovery_threads_per_data_dir: 1

    # The number of background threads to use for log cleaning
    kafka_log_cleaner_threads: 1

    ############################# Internal Topic Settings #############################

    # The replication factor for the group metadata internal topics "__consumer_offsets" and "__transaction_state"
    # For anything other than development testing, a value greater than 1 is recommended for to ensure availability such as 3.
    kafka_offsets_topic_replication_factor: 3
    kafka_transaction_state_log_replication_factor: 3
    kafka_transaction_state_log_min_isr: 2

    ############################# Log Flush Policy #############################

    kafka_log_flush_interval_messages: 20000
    kafka_log_flush_interval_ms: 1000

    ############################# Log Retention Policy #############################

    # The minimum age of a log file to be eligible for deletion
    kafka_log_retention_hours: 72

    # The maximum size of a log segment file. When this size is reached a new log segment will be created.
    kafka_log_segment_bytes: 536870912

    # The interval at which log segments are checked to see if they can be deleted according
    # to the retention policies
    kafka_log_retention_check_interval_ms: 300000

    # The amount of time to sleep when there are no logs to clean
    kafka_log_cleaner_backoff_ms: 15000

    ############################# KRaft #############################

    # If KRaft is enabled, ignore the Zookeeper configuration settings
    kraft_listener_port: 9093
    kraft_controller_quorum_voters: "1@10.0.20.21:9093,2@10.0.20.22:9093,3@10.0.20.23:9093"
    kraft_cluster_uuid: "ElI5G4G-TWGCJKDky-kaGQ"

    ############################# Zookeeper #############################

    # Zookeeper connection string (see zookeeper docs for details).
    # This is a comma separated host:port pairs, each corresponding to a zk
    # server. e.g. "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002".
    # You can also append an optional chroot string to the urls to specify the
    # root directory for all kafka znodes.
    # kafka_zookeeper_connect: "10.0.20.21:8181,10.0.20.22:8181,10.0.20.23:8181"

    # the directory where the snapshot is stored.
    # kafka_zookeeper_data_dir: /u01/data/zookeeper
    # the port at which the clients will connect
    # kafka_zookeeper_client_port: 8181

    # define servers ip and internal ports to zookeeper, for example:
    # server.1=zookeeper1:2888:3888
    # kafka_zookeeper_internal_port1: 2888
    # kafka_zookeeper_internal_port2: 3888
    # disable the per-ip limit on the number of connections since this is a non-production config
    # kafka_zookeeper_max_client_cnxns: 10000

    ############################# Timeout #############################

    # Timeout in ms for connecting to zookeeper
    kafka_zookeeper_connection_timeout_ms: 120000
    kafka_zookeeper_session_timeout_ms: 120000

    # Offset commit will be delayed until all replicas for the offsets topic receive the commit or this timeout is reached.
    # This is similar to the producer request timeout.
    kafka_offsets_commit_timeout_ms: 5000

    # Max wait time for each fetcher request issued by follower replicas. This value should always be less than
    # the replica.lag.time.max.ms at all times to prevent frequent shrinking of ISR for low throughput topics
    kafka_replica_fetch_wait_max_ms: 500
    kafka_replica_fetch_max_bytes: 300000

    ############################# Group Coordinator Settings #############################

    kafka_group_initial_rebalance_delay_ms: 3000

    ############################## Customized configuration ###############################

    kafka_message_max_bytes: 300000
    kafka_min_insync_replicas: 2
    kafka_queued_max_requests: 1000
    kafka_unclean_leader_election_enable: false

    # Kafka log4j2.properties
    kafka_log_max_file_size: 50MB
    kafka_log_max_backup_index: 5
